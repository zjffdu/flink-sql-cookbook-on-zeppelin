{
  "paragraphs": [
    {
      "text": "%md\n\n![Twitter Badge](https://img.shields.io/badge/Flink%20Version-1.10%2B-lightgrey)\n\n\u003e :bulb: This example will show how to use `WATERMARK`s to work with timestamps in records. \n\nThe source table (`doctor_sightings`) is backed by the [`faker` connector](https://flink-packages.org/packages/flink-faker), which continuously generates rows in memory based on Java Faker expressions.\n\nThe [previous recipe](../01_group_by_window/01_group_by_window.md) showed how a `TUMBLE` group window makes it simple to aggregate time-series data.\t \n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) is a renegade time lord who travels through space and time in a [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS).\nAs different versions of the Doctor travel through time, various people log their sightings.\nWe want to track how many times each version of the Doctor is seen each minute. \t \nUnlike the previous recipe, these records have an embedded timestamp we need to use to perform our calculation. \t \n\nMore often than not, most data will come with embedded timestamps that we want to use for our time series calculations.\tWe call this timestamp an [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/docs/learn-flink/streaming_analytics/#event-time-and-watermarks).\t \n  \nEvent time represents when something actually happened in the real world.\nAnd it is unique because it is quasi-monotonically increasing; we generally see things that happened earlier before seeing things that happen later. Of course, data will never be perfectly ordered (systems go down, networks are laggy, doctor sighting take time to postmark and mail), and there will be some out-of-orderness in our data. \t \n\nFlink can account for all these variabilities using a [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) attribute in the tables DDL. The watermark signifies a column as the table\u0027s event time attribute and tells Flink how out of order we expect our data. \t \n \nIn the Doctor\u0027s case, we expect all records to arrive within 15 seconds when the sighting occurs.\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:09:06.519",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://img.shields.io/badge/Flink%20Version-1.10%2B-lightgrey\" alt\u003d\"Twitter Badge\" /\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eğŸ’¡ This example will show how to use \u003ccode\u003eWATERMARK\u003c/code\u003es to work with timestamps in records.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe source table (\u003ccode\u003edoctor_sightings\u003c/code\u003e) is backed by the \u003ca href\u003d\"https://flink-packages.org/packages/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e, which continuously generates rows in memory based on Java Faker expressions.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href\u003d\"../01_group_by_window/01_group_by_window.md\"\u003eprevious recipe\u003c/a\u003e showed how a \u003ccode\u003eTUMBLE\u003c/code\u003e group window makes it simple to aggregate time-series data.\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor\"\u003eThe Doctor\u003c/a\u003e is a renegade time lord who travels through space and time in a \u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS\"\u003eTARDIS\u003c/a\u003e.\u003cbr /\u003e\nAs different versions of the Doctor travel through time, various people log their sightings.\u003cbr /\u003e\nWe want to track how many times each version of the Doctor is seen each minute.\u003cbr /\u003e\nUnlike the previous recipe, these records have an embedded timestamp we need to use to perform our calculation.\u003c/p\u003e\n\u003cp\u003eMore often than not, most data will come with embedded timestamps that we want to use for our time series calculations.\tWe call this timestamp an \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/docs/learn-flink/streaming_analytics/#event-time-and-watermarks\"\u003eevent-time attribute\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEvent time represents when something actually happened in the real world.\u003cbr /\u003e\nAnd it is unique because it is quasi-monotonically increasing; we generally see things that happened earlier before seeing things that happen later. Of course, data will never be perfectly ordered (systems go down, networks are laggy, doctor sighting take time to postmark and mail), and there will be some out-of-orderness in our data.\u003c/p\u003e\n\u003cp\u003eFlink can account for all these variabilities using a \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time\"\u003eWATERMARK\u003c/a\u003e attribute in the tables DDL. The watermark signifies a column as the table\u0026rsquo;s event time attribute and tells Flink how out of order we expect our data.\u003c/p\u003e\n\u003cp\u003eIn the Doctor\u0026rsquo;s case, we expect all records to arrive within 15 seconds when the sighting occurs.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614312342228_1171087041",
      "id": "paragraph_1614312342228_1171087041",
      "dateCreated": "2021-02-26 12:05:42.228",
      "dateStarted": "2021-10-08 16:09:06.521",
      "dateFinished": "2021-10-08 16:09:06.532",
      "status": "FINISHED"
    },
    {
      "text": "%md\n\næœ¬ä¾‹å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `WATERMARK` æ¥å¤„ç†è®°å½•ä¸­çš„æ—¶é—´æˆ³ã€‚\n\nä¾‹å­ä¸­ä½¿ç”¨çš„ source è¡¨`server_logs` çš„æ•°æ®æ˜¯åˆ©ç”¨  [`faker` connector](https://github.com/knaufk/flink-faker) äº§ç”Ÿçš„ï¼Œå®ƒåŸºäº Java Faker è¡¨è¾¾å¼ä¸æ–­çš„åœ¨å†…å­˜ä¸­ç”Ÿæˆæ•°æ®ã€‚\n\nä¹‹å‰çš„ä¾‹å­å±•ç¤ºäº† `TUMBLE` çª—å£å¦‚ä½•ä½¿æ—¶é—´åºåˆ—æ•°æ®çš„èšåˆå˜å¾—ç®€å•ã€‚\n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) æ˜¯ä¸€ä¸ªå›é€†çš„æ—¶é—´é¢†ä¸»ï¼Œä»–ä½¿ç”¨ [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS) åœ¨æ—¶é—´å’Œç©ºé—´ä¸­ç©¿æ¢­æ—…è¡Œã€‚ä¸åŒç‰ˆæœ¬çš„åšå£«ç©¿è¶Šåœ¨æ—¶é—´ä¸­ï¼Œä¸åŒçš„äººè®°å½•ç€ä»–ä»¬ç›®å‡»åˆ°çš„åšå£«ä»¥åŠç›®å‡»çš„æ—¶é—´ã€‚æˆ‘ä»¬è¦è¿½è¸ªæ¯ç§ç‰ˆæœ¬çš„åšå£«æ¯åˆ†é’Ÿè¢«ç›®å‡»çš„æ¬¡æ•°ã€‚ä¸å‰é¢çš„ä¾‹å­ä¸åŒï¼Œè¿™äº›è®°å½•æœ‰ä¸€ä¸ªåµŒå…¥çš„æ—¶é—´æˆ³æˆ‘ä»¬éœ€è¦ä½¿ç”¨å®ƒæ¥è®¡ç®—ã€‚\n\né€šå¸¸ï¼Œå¾ˆå¤šæ•°æ®æœ¬èº«å°±æºå¸¦æˆ‘ä»¬éœ€è¦ç”¨æ¥è®¡ç®—æ—¶é—´åºåˆ—çš„æ—¶é—´æˆ³ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸º  [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks).\n\nEvent time(äº‹ä»¶äº‹ä»¶) ä»£è¡¨äº†äº‹ä»¶åœ¨çœŸå®ä¸–ç•Œå®é™…å‘ç”Ÿçš„æ—¶é—´ã€‚å®ƒæ˜¯å”¯ä¸€çš„å› ä¸ºå®ƒæ˜¯å•è°ƒé€’å¢çš„ï¼›æˆ‘ä»¬é€šå¸¸å…ˆçœ‹åˆ°ä¹‹å‰å‘ç”Ÿçš„äº‹ç„¶åç„¶åçœ‹åˆ°åé¢å‘ç”Ÿçš„äº‹ã€‚å½“ç„¶ï¼Œæ•°æ®é›†ä¸å¯èƒ½éƒ½è¢«å®Œç¾çš„æ’å¥½åºï¼ˆç³»ç»Ÿå®•æœºï¼Œç½‘ç»œå»¶è¿Ÿï¼Œdoctor ç›®å‡»è¯è´¹é‚®å¯„æ—¶é—´ï¼‰ï¼Œæˆ‘ä»¬çš„æ•°æ®ä¸­å°†åŒ…å«ä¸€äº›æ— åºçš„è®°å½•ã€‚\n\nFLink å¯ä»¥åœ¨è¡¨çš„ DDL ä¸­ä½¿ç”¨  [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) æ¥å°†è¿™äº›å˜æ•°è€ƒè™‘è¿›æ¥ã€‚watermark ä½œä¸ºæ—¶é—´å±æ€§è¡¨ç¤ºä¸ºè¡¨ä¸­çš„ä¸€ä¸ªå­—æ®µï¼Œå¹¶å‘Šè¯‰ Flink æˆ‘ä»¬æœŸæœ›çš„æ•°æ®çš„æ’åºç¨‹åº¦ã€‚\n\nåœ¨ä¸‹é¢çš„ Doctor ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœŸæœ›æ‰€æœ‰çš„æ•°æ®åœ¨ç›®å‡»å‘ç”Ÿå15ç§’å†…åˆ°è¾¾ã€‚\n\n\u003e èƒŒæ™¯ä»‹ç» ã€Šç¥ç§˜åšå£«ã€‹ï¼ˆDoctor Whoï¼‰æ˜¯ä¸€éƒ¨ç”±è‹±å›½BBCå‡ºå“çš„ç§‘å¹»ç”µè§†å‰§ã€‚æ•…äº‹è®²è¿°äº†ä¸€ä½è‡ªç§°ä¸ºâ€œåšå£«â€ï¼ˆThe Doctorï¼‰çš„æ—¶é—´é¢†ä¸»ç”¨ä»–ä¼ªè£…æˆ20ä¸–çºª50å¹´ä»£è‹±å›½è­¦äº­çš„æ—¶é—´æœºå™¨å¡”è¿ªæ–¯ï¼ˆTARDISï¼Œå³â€Time And Relative Dimension(s) In Spaceâ€œçš„ç¼©å†™ï¼‰ä¸å…¶æ­æ¡£åœ¨æ—¶é—´ã€ç©ºé—´æ¢ç´¢æ‚ æ¸¸ã€æƒ©æ¶æ‰¬å–„ã€æ‹¯æ•‘æ–‡æ˜ã€å¸®åŠ©å¼±å°çš„æ•…äº‹ã€‚\n[ç¥ç§˜åšå£«](https://baike.baidu.com/item/%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB/82613?fromtitle\u003ddoctor%20who\u0026fromid\u003d3946220\u0026fr\u003daladdin)\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:53:31.696",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eæœ¬ä¾‹å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ \u003ccode\u003eWATERMARK\u003c/code\u003e æ¥å¤„ç†è®°å½•ä¸­çš„æ—¶é—´æˆ³ã€‚\u003c/p\u003e\n\u003cp\u003eä¾‹å­ä¸­ä½¿ç”¨çš„ source è¡¨\u003ccode\u003eserver_logs\u003c/code\u003e çš„æ•°æ®æ˜¯åˆ©ç”¨  \u003ca href\u003d\"https://github.com/knaufk/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e äº§ç”Ÿçš„ï¼Œå®ƒåŸºäº Java Faker è¡¨è¾¾å¼ä¸æ–­çš„åœ¨å†…å­˜ä¸­ç”Ÿæˆæ•°æ®ã€‚\u003c/p\u003e\n\u003cp\u003eä¹‹å‰çš„ä¾‹å­å±•ç¤ºäº† \u003ccode\u003eTUMBLE\u003c/code\u003e çª—å£å¦‚ä½•ä½¿æ—¶é—´åºåˆ—æ•°æ®çš„èšåˆå˜å¾—ç®€å•ã€‚\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor\"\u003eThe Doctor\u003c/a\u003e æ˜¯ä¸€ä¸ªå›é€†çš„æ—¶é—´é¢†ä¸»ï¼Œä»–ä½¿ç”¨ \u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS\"\u003eTARDIS\u003c/a\u003e åœ¨æ—¶é—´å’Œç©ºé—´ä¸­ç©¿æ¢­æ—…è¡Œã€‚ä¸åŒç‰ˆæœ¬çš„åšå£«ç©¿è¶Šåœ¨æ—¶é—´ä¸­ï¼Œä¸åŒçš„äººè®°å½•ç€ä»–ä»¬ç›®å‡»åˆ°çš„åšå£«ä»¥åŠç›®å‡»çš„æ—¶é—´ã€‚æˆ‘ä»¬è¦è¿½è¸ªæ¯ç§ç‰ˆæœ¬çš„åšå£«æ¯åˆ†é’Ÿè¢«ç›®å‡»çš„æ¬¡æ•°ã€‚ä¸å‰é¢çš„ä¾‹å­ä¸åŒï¼Œè¿™äº›è®°å½•æœ‰ä¸€ä¸ªåµŒå…¥çš„æ—¶é—´æˆ³æˆ‘ä»¬éœ€è¦ä½¿ç”¨å®ƒæ¥è®¡ç®—ã€‚\u003c/p\u003e\n\u003cp\u003eé€šå¸¸ï¼Œå¾ˆå¤šæ•°æ®æœ¬èº«å°±æºå¸¦æˆ‘ä»¬éœ€è¦ç”¨æ¥è®¡ç®—æ—¶é—´åºåˆ—çš„æ—¶é—´æˆ³ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸º  \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks\"\u003eevent-time attribute\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEvent time(äº‹ä»¶äº‹ä»¶) ä»£è¡¨äº†äº‹ä»¶åœ¨çœŸå®ä¸–ç•Œå®é™…å‘ç”Ÿçš„æ—¶é—´ã€‚å®ƒæ˜¯å”¯ä¸€çš„å› ä¸ºå®ƒæ˜¯å•è°ƒé€’å¢çš„ï¼›æˆ‘ä»¬é€šå¸¸å…ˆçœ‹åˆ°ä¹‹å‰å‘ç”Ÿçš„äº‹ç„¶åç„¶åçœ‹åˆ°åé¢å‘ç”Ÿçš„äº‹ã€‚å½“ç„¶ï¼Œæ•°æ®é›†ä¸å¯èƒ½éƒ½è¢«å®Œç¾çš„æ’å¥½åºï¼ˆç³»ç»Ÿå®•æœºï¼Œç½‘ç»œå»¶è¿Ÿï¼Œdoctor ç›®å‡»è¯è´¹é‚®å¯„æ—¶é—´ï¼‰ï¼Œæˆ‘ä»¬çš„æ•°æ®ä¸­å°†åŒ…å«ä¸€äº›æ— åºçš„è®°å½•ã€‚\u003c/p\u003e\n\u003cp\u003eFLink å¯ä»¥åœ¨è¡¨çš„ DDL ä¸­ä½¿ç”¨  \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time\"\u003eWATERMARK\u003c/a\u003e æ¥å°†è¿™äº›å˜æ•°è€ƒè™‘è¿›æ¥ã€‚watermark ä½œä¸ºæ—¶é—´å±æ€§è¡¨ç¤ºä¸ºè¡¨ä¸­çš„ä¸€ä¸ªå­—æ®µï¼Œå¹¶å‘Šè¯‰ Flink æˆ‘ä»¬æœŸæœ›çš„æ•°æ®çš„æ’åºç¨‹åº¦ã€‚\u003c/p\u003e\n\u003cp\u003eåœ¨ä¸‹é¢çš„ Doctor ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœŸæœ›æ‰€æœ‰çš„æ•°æ®åœ¨ç›®å‡»å‘ç”Ÿå15ç§’å†…åˆ°è¾¾ã€‚\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eèƒŒæ™¯ä»‹ç» ã€Šç¥ç§˜åšå£«ã€‹ï¼ˆDoctor Whoï¼‰æ˜¯ä¸€éƒ¨ç”±è‹±å›½BBCå‡ºå“çš„ç§‘å¹»ç”µè§†å‰§ã€‚æ•…äº‹è®²è¿°äº†ä¸€ä½è‡ªç§°ä¸ºâ€œåšå£«â€ï¼ˆThe Doctorï¼‰çš„æ—¶é—´é¢†ä¸»ç”¨ä»–ä¼ªè£…æˆ20ä¸–çºª50å¹´ä»£è‹±å›½è­¦äº­çš„æ—¶é—´æœºå™¨å¡”è¿ªæ–¯ï¼ˆTARDISï¼Œå³â€Time And Relative Dimension(s) In Spaceâ€œçš„ç¼©å†™ï¼‰ä¸å…¶æ­æ¡£åœ¨æ—¶é—´ã€ç©ºé—´æ¢ç´¢æ‚ æ¸¸ã€æƒ©æ¶æ‰¬å–„ã€æ‹¯æ•‘æ–‡æ˜ã€å¸®åŠ©å¼±å°çš„æ•…äº‹ã€‚\u003cbr /\u003e\n\u003ca href\u003d\"https://baike.baidu.com/item/%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB/82613?fromtitle\u003ddoctor%20who\u0026amp;fromid\u003d3946220\u0026amp;fr\u003daladdin\"\u003eç¥ç§˜åšå£«\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615107347152_1462984888",
      "id": "paragraph_1615107347152_1462984888",
      "dateCreated": "2021-03-07 08:55:47.152",
      "dateStarted": "2021-03-18 15:53:31.696",
      "dateFinished": "2021-03-18 15:53:31.715",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\nDROP TABLE IF EXISTS doctor_sightings;\n\nCREATE TABLE doctor_sightings (\n  doctor        STRING,\n  sighting_time TIMESTAMP(3),\n  WATERMARK FOR sighting_time AS sighting_time - INTERVAL \u002715\u0027 SECONDS\n)\nWITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027, \n  \u0027fields.doctor.expression\u0027 \u003d \u0027#{dr_who.the_doctors}\u0027,\n  \u0027fields.sighting_time.expression\u0027 \u003d \u0027#{date.past \u0027\u002715\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027\n);\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:09:14.931",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268686829_1056396133",
      "id": "paragraph_1614268686829_1056396133",
      "dateCreated": "2021-02-25 23:58:06.829",
      "dateStarted": "2021-10-08 16:09:14.933",
      "dateFinished": "2021-10-08 16:09:46.721",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 100;\n    \n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:18:46.802",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "doctor": "string",
                      "sighting_time": "string",
                      "sightings": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "doctor\tsighting_time\tsightings\nEighth Doctor\t2021-10-08 21:18:59.999\t16482\nEleventh Doctor\t2021-10-08 21:18:59.999\t16396\nFifth Doctor\t2021-10-08 21:18:59.999\t16614\nFirst Doctor\t2021-10-08 21:18:59.999\t16501\nFourth Doctor\t2021-10-08 21:18:59.999\t16609\nNinth Doctor\t2021-10-08 21:18:59.999\t16374\nSecond Doctor\t2021-10-08 21:18:59.999\t16668\nSeventh Doctor\t2021-10-08 21:18:59.999\t16573\nSixth Doctor\t2021-10-08 21:18:59.999\t16658\nTenth Doctor\t2021-10-08 21:18:59.999\t16422\nThird Doctor\t2021-10-08 21:18:59.999\t16631\nThirteenth Doctor\t2021-10-08 21:18:59.999\t16502\nTwelfth Doctor\t2021-10-08 21:18:59.999\t16494\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 100\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:177)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:109)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:86)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callSelect(FlinkSqlInterpreter.java:494)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callCommand(FlinkSqlInterpreter.java:257)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.runSqlList(FlinkSqlInterpreter.java:151)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.internalInterpret(FlinkSqlInterpreter.java:109)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:55)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:849)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:741)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.flink.client.deployment.application.UnsuccessfulExecutionException: Application Status: CANCELED\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:71)\n\tat org.apache.flink.client.deployment.application.EmbeddedJobClient.lambda$getJobExecutionResult$2(EmbeddedJobClient.java:136)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.client.deployment.application.JobStatusPollingUtils.lambda$null$2(JobStatusPollingUtils.java:101)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:250)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:146)\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:60)\n\t... 52 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "https://knox.c-fa375384f1f481e0.cn-hongkong.emr.aliyuncs.com:8443/gateway/cluster-topo/yarn/proxy/application_1628498781174_4095/#/job/a588073e4e618d2c40c86cf533d5e29a"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268697349_106287994",
      "id": "paragraph_1614268697349_106287994",
      "dateCreated": "2021-02-25 23:58:17.349",
      "dateStarted": "2021-10-08 16:18:46.804",
      "dateFinished": "2021-10-08 16:19:23.466",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-25 23:58:38.971",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268718968_1902190862",
      "id": "paragraph_1614268718968_1902190862",
      "dateCreated": "2021-02-25 23:58:38.971",
      "status": "READY"
    }
  ],
  "name": "02 Watermarks",
  "id": "2FXSSGYS2",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}