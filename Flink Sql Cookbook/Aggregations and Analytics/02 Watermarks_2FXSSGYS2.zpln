{
  "paragraphs": [
    {
      "text": "%md\n\n![Twitter Badge](https://img.shields.io/badge/Flink%20Version-1.10%2B-lightgrey)\n\n\u003e :bulb: This example will show how to use `WATERMARK`s to work with timestamps in records. \n\nThe source table (`doctor_sightings`) is backed by the [`faker` connector](https://flink-packages.org/packages/flink-faker), which continuously generates rows in memory based on Java Faker expressions.\n\nThe [previous recipe](../01_group_by_window/01_group_by_window.md) showed how a `TUMBLE` group window makes it simple to aggregate time-series data.\t \n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) is a renegade time lord who travels through space and time in a [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS).\nAs different versions of the Doctor travel through time, various people log their sightings.\nWe want to track how many times each version of the Doctor is seen each minute. \t \nUnlike the previous recipe, these records have an embedded timestamp we need to use to perform our calculation. \t \n\nMore often than not, most data will come with embedded timestamps that we want to use for our time series calculations.\tWe call this timestamp an [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/docs/learn-flink/streaming_analytics/#event-time-and-watermarks).\t \n  \nEvent time represents when something actually happened in the real world.\nAnd it is unique because it is quasi-monotonically increasing; we generally see things that happened earlier before seeing things that happen later. Of course, data will never be perfectly ordered (systems go down, networks are laggy, doctor sighting take time to postmark and mail), and there will be some out-of-orderness in our data. \t \n\nFlink can account for all these variabilities using a [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) attribute in the tables DDL. The watermark signifies a column as the table\u0027s event time attribute and tells Flink how out of order we expect our data. \t \n \nIn the Doctor\u0027s case, we expect all records to arrive within 15 seconds when the sighting occurs.\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:09:06.519",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://img.shields.io/badge/Flink%20Version-1.10%2B-lightgrey\" alt\u003d\"Twitter Badge\" /\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e💡 This example will show how to use \u003ccode\u003eWATERMARK\u003c/code\u003es to work with timestamps in records.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe source table (\u003ccode\u003edoctor_sightings\u003c/code\u003e) is backed by the \u003ca href\u003d\"https://flink-packages.org/packages/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e, which continuously generates rows in memory based on Java Faker expressions.\u003c/p\u003e\n\u003cp\u003eThe \u003ca href\u003d\"../01_group_by_window/01_group_by_window.md\"\u003eprevious recipe\u003c/a\u003e showed how a \u003ccode\u003eTUMBLE\u003c/code\u003e group window makes it simple to aggregate time-series data.\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor\"\u003eThe Doctor\u003c/a\u003e is a renegade time lord who travels through space and time in a \u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS\"\u003eTARDIS\u003c/a\u003e.\u003cbr /\u003e\nAs different versions of the Doctor travel through time, various people log their sightings.\u003cbr /\u003e\nWe want to track how many times each version of the Doctor is seen each minute.\u003cbr /\u003e\nUnlike the previous recipe, these records have an embedded timestamp we need to use to perform our calculation.\u003c/p\u003e\n\u003cp\u003eMore often than not, most data will come with embedded timestamps that we want to use for our time series calculations.\tWe call this timestamp an \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/docs/learn-flink/streaming_analytics/#event-time-and-watermarks\"\u003eevent-time attribute\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEvent time represents when something actually happened in the real world.\u003cbr /\u003e\nAnd it is unique because it is quasi-monotonically increasing; we generally see things that happened earlier before seeing things that happen later. Of course, data will never be perfectly ordered (systems go down, networks are laggy, doctor sighting take time to postmark and mail), and there will be some out-of-orderness in our data.\u003c/p\u003e\n\u003cp\u003eFlink can account for all these variabilities using a \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time\"\u003eWATERMARK\u003c/a\u003e attribute in the tables DDL. The watermark signifies a column as the table\u0026rsquo;s event time attribute and tells Flink how out of order we expect our data.\u003c/p\u003e\n\u003cp\u003eIn the Doctor\u0026rsquo;s case, we expect all records to arrive within 15 seconds when the sighting occurs.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614312342228_1171087041",
      "id": "paragraph_1614312342228_1171087041",
      "dateCreated": "2021-02-26 12:05:42.228",
      "dateStarted": "2021-10-08 16:09:06.521",
      "dateFinished": "2021-10-08 16:09:06.532",
      "status": "FINISHED"
    },
    {
      "text": "%md\n\n本例将展示如何使用 `WATERMARK` 来处理记录中的时间戳。\n\n例子中使用的 source 表`server_logs` 的数据是利用  [`faker` connector](https://github.com/knaufk/flink-faker) 产生的，它基于 Java Faker 表达式不断的在内存中生成数据。\n\n之前的例子展示了 `TUMBLE` 窗口如何使时间序列数据的聚合变得简单。\n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) 是一个叛逆的时间领主，他使用 [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS) 在时间和空间中穿梭旅行。不同版本的博士穿越在时间中，不同的人记录着他们目击到的博士以及目击的时间。我们要追踪每种版本的博士每分钟被目击的次数。与前面的例子不同，这些记录有一个嵌入的时间戳我们需要使用它来计算。\n\n通常，很多数据本身就携带我们需要用来计算时间序列的时间戳。我们称之为  [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks).\n\nEvent time(事件事件) 代表了事件在真实世界实际发生的时间。它是唯一的因为它是单调递增的；我们通常先看到之前发生的事然后然后看到后面发生的事。当然，数据集不可能都被完美的排好序（系统宕机，网络延迟，doctor 目击话费邮寄时间），我们的数据中将包含一些无序的记录。\n\nFLink 可以在表的 DDL 中使用  [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) 来将这些变数考虑进来。watermark 作为时间属性表示为表中的一个字段，并告诉 Flink 我们期望的数据的排序程度。\n\n在下面的 Doctor 例子中，我们期望所有的数据在目击发生后15秒内到达。\n\n\u003e 背景介绍 《神秘博士》（Doctor Who）是一部由英国BBC出品的科幻电视剧。故事讲述了一位自称为“博士”（The Doctor）的时间领主用他伪装成20世纪50年代英国警亭的时间机器塔迪斯（TARDIS，即”Time And Relative Dimension(s) In Space“的缩写）与其搭档在时间、空间探索悠游、惩恶扬善、拯救文明、帮助弱小的故事。\n[神秘博士](https://baike.baidu.com/item/%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB/82613?fromtitle\u003ddoctor%20who\u0026fromid\u003d3946220\u0026fr\u003daladdin)\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:53:31.696",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e本例将展示如何使用 \u003ccode\u003eWATERMARK\u003c/code\u003e 来处理记录中的时间戳。\u003c/p\u003e\n\u003cp\u003e例子中使用的 source 表\u003ccode\u003eserver_logs\u003c/code\u003e 的数据是利用  \u003ca href\u003d\"https://github.com/knaufk/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e 产生的，它基于 Java Faker 表达式不断的在内存中生成数据。\u003c/p\u003e\n\u003cp\u003e之前的例子展示了 \u003ccode\u003eTUMBLE\u003c/code\u003e 窗口如何使时间序列数据的聚合变得简单。\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor\"\u003eThe Doctor\u003c/a\u003e 是一个叛逆的时间领主，他使用 \u003ca href\u003d\"https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS\"\u003eTARDIS\u003c/a\u003e 在时间和空间中穿梭旅行。不同版本的博士穿越在时间中，不同的人记录着他们目击到的博士以及目击的时间。我们要追踪每种版本的博士每分钟被目击的次数。与前面的例子不同，这些记录有一个嵌入的时间戳我们需要使用它来计算。\u003c/p\u003e\n\u003cp\u003e通常，很多数据本身就携带我们需要用来计算时间序列的时间戳。我们称之为  \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks\"\u003eevent-time attribute\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEvent time(事件事件) 代表了事件在真实世界实际发生的时间。它是唯一的因为它是单调递增的；我们通常先看到之前发生的事然后然后看到后面发生的事。当然，数据集不可能都被完美的排好序（系统宕机，网络延迟，doctor 目击话费邮寄时间），我们的数据中将包含一些无序的记录。\u003c/p\u003e\n\u003cp\u003eFLink 可以在表的 DDL 中使用  \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time\"\u003eWATERMARK\u003c/a\u003e 来将这些变数考虑进来。watermark 作为时间属性表示为表中的一个字段，并告诉 Flink 我们期望的数据的排序程度。\u003c/p\u003e\n\u003cp\u003e在下面的 Doctor 例子中，我们期望所有的数据在目击发生后15秒内到达。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e背景介绍 《神秘博士》（Doctor Who）是一部由英国BBC出品的科幻电视剧。故事讲述了一位自称为“博士”（The Doctor）的时间领主用他伪装成20世纪50年代英国警亭的时间机器塔迪斯（TARDIS，即”Time And Relative Dimension(s) In Space“的缩写）与其搭档在时间、空间探索悠游、惩恶扬善、拯救文明、帮助弱小的故事。\u003cbr /\u003e\n\u003ca href\u003d\"https://baike.baidu.com/item/%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB/82613?fromtitle\u003ddoctor%20who\u0026amp;fromid\u003d3946220\u0026amp;fr\u003daladdin\"\u003e神秘博士\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615107347152_1462984888",
      "id": "paragraph_1615107347152_1462984888",
      "dateCreated": "2021-03-07 08:55:47.152",
      "dateStarted": "2021-03-18 15:53:31.696",
      "dateFinished": "2021-03-18 15:53:31.715",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\nDROP TABLE IF EXISTS doctor_sightings;\n\nCREATE TABLE doctor_sightings (\n  doctor        STRING,\n  sighting_time TIMESTAMP(3),\n  WATERMARK FOR sighting_time AS sighting_time - INTERVAL \u002715\u0027 SECONDS\n)\nWITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027, \n  \u0027fields.doctor.expression\u0027 \u003d \u0027#{dr_who.the_doctors}\u0027,\n  \u0027fields.sighting_time.expression\u0027 \u003d \u0027#{date.past \u0027\u002715\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027\n);\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:09:14.931",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268686829_1056396133",
      "id": "paragraph_1614268686829_1056396133",
      "dateCreated": "2021-02-25 23:58:06.829",
      "dateStarted": "2021-10-08 16:09:14.933",
      "dateFinished": "2021-10-08 16:09:46.721",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 100;\n    \n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:18:46.802",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "doctor": "string",
                      "sighting_time": "string",
                      "sightings": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "doctor\tsighting_time\tsightings\nEighth Doctor\t2021-10-08 21:18:59.999\t16482\nEleventh Doctor\t2021-10-08 21:18:59.999\t16396\nFifth Doctor\t2021-10-08 21:18:59.999\t16614\nFirst Doctor\t2021-10-08 21:18:59.999\t16501\nFourth Doctor\t2021-10-08 21:18:59.999\t16609\nNinth Doctor\t2021-10-08 21:18:59.999\t16374\nSecond Doctor\t2021-10-08 21:18:59.999\t16668\nSeventh Doctor\t2021-10-08 21:18:59.999\t16573\nSixth Doctor\t2021-10-08 21:18:59.999\t16658\nTenth Doctor\t2021-10-08 21:18:59.999\t16422\nThird Doctor\t2021-10-08 21:18:59.999\t16631\nThirteenth Doctor\t2021-10-08 21:18:59.999\t16502\nTwelfth Doctor\t2021-10-08 21:18:59.999\t16494\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 100\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:177)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:109)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:86)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callSelect(FlinkSqlInterpreter.java:494)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callCommand(FlinkSqlInterpreter.java:257)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.runSqlList(FlinkSqlInterpreter.java:151)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.internalInterpret(FlinkSqlInterpreter.java:109)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:55)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:849)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:741)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.flink.client.deployment.application.UnsuccessfulExecutionException: Application Status: CANCELED\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:71)\n\tat org.apache.flink.client.deployment.application.EmbeddedJobClient.lambda$getJobExecutionResult$2(EmbeddedJobClient.java:136)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.client.deployment.application.JobStatusPollingUtils.lambda$null$2(JobStatusPollingUtils.java:101)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:250)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:146)\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:60)\n\t... 52 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "https://knox.c-fa375384f1f481e0.cn-hongkong.emr.aliyuncs.com:8443/gateway/cluster-topo/yarn/proxy/application_1628498781174_4095/#/job/a588073e4e618d2c40c86cf533d5e29a"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268697349_106287994",
      "id": "paragraph_1614268697349_106287994",
      "dateCreated": "2021-02-25 23:58:17.349",
      "dateStarted": "2021-10-08 16:18:46.804",
      "dateFinished": "2021-10-08 16:19:23.466",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-25 23:58:38.971",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268718968_1902190862",
      "id": "paragraph_1614268718968_1902190862",
      "dateCreated": "2021-02-25 23:58:38.971",
      "status": "READY"
    }
  ],
  "name": "02 Watermarks",
  "id": "2FXSSGYS2",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}