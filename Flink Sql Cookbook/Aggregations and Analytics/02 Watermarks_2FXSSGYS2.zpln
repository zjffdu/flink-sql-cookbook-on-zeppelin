{
  "paragraphs": [
    {
      "text": "%md\n\nThis example will show how to use `WATERMARK`s to work with timestamps in records. \n\nThe source table (`doctor_sightings`) is backed by the [`faker` connector](https://github.com/knaufk/flink-faker), which continuously generates rows in memory based on Java Faker expressions.\n\nThe previous recipe showed how a `TUMBLE` group window makes it simple to aggregate time-series data.\t \n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) is a renegade time lord who travels through space and time in a [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS). As different versions of the Doctor travel through time, various people log their sightings. We want to track how many times each version of the Doctor is seen each minute. Unlike the previous recipe, these records have an embedded timestamp we need to use to perform our calculation. \t \n\nMore often than not, most data will come with embedded timestamps that we want to use for our time series calculations.\tWe call this timestamp an [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks).\t \n  \nEvent time represents when something actually happened in the real world. And it is unique because it is quasi-monotonically increasing; we generally see things that happened earlier before seeing things that happen later. Of course, data will never be perfectly ordered (systems go down, networks are laggy, doctor sighting take time to postmark and mail), and there will be some out-of-orderness in our data. \t \n\nFlink can account for all these variabilities using a [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) attribute in the tables DDL. The watermark signifies a column as the table\u0027s event time attribute and tells Flink how out of order we expect our data. \t \n \nIn the Doctor\u0027s case, we expect all records to arrive within 15 seconds when the sighting occurs.\n\n本例将展示如何使用 `WATERMARK` 来处理记录中的时间戳。\n\n例子中使用的 source 表`server_logs` 的数据是利用  [`faker` connector](https://github.com/knaufk/flink-faker) 产生的，它基于 Java Faker 表达式不断的在内存中生成数据。\n\n之前的例子展示了 `TUMBLE` 窗口如何使时间序列数据的聚合变得简单。随着不同版本的医生穿越时间，不同的人记录他们的目击。我们要追踪每种版本的医生每分钟被目击的次数。与前面的例子不同，这些记录有一个嵌入的时间戳我们需要使用它来计算。\n\n[The Doctor](https://tardis.fandom.com/wiki/The_Doctor) 是一个叛逆的时间领主，他使用 [TARDIS](https://tardis.fandom.com/wiki/The_Doctor%27s_TARDIS) 在时间和空间中穿梭旅行。\n\n通常，很多数据本身就携带我们需要用来计算时间序列的时间戳。我们称之为  [event-time attribute](https://ci.apache.org/projects/flink/flink-docs-stable/learn-flink/streaming_analytics.html#event-time-and-watermarks).\n\nEvent time 代表了事件在真实世界实际发生的时间。他是唯一的因为他是单调递增的；我们通常先看到之前发生的事然后然后后面发生的事。当然，数据集不可能被完美的排好序（系统宕机，网络延迟，doctor 目击话费邮寄时间），我们的数据中将包含一些无序的记录。\n\nFLink 可以在表的 DDL 中使用  [WATERMARK](https://docs.ververica.com/user_guide/sql_development/table_view.html#event-time) 来将这些变数考虑进来。watermark作为时间时间属性表示为表中的一个字段，并告诉 Flink 我们期望的数据的排序程度。\n\n在下面的 Doctor 例子中，我们期望所有的数据在目击发生后15秒内到达。\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 14:53:15.582",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614312342228_1171087041",
      "id": "paragraph_1614312342228_1171087041",
      "dateCreated": "2021-02-26 12:05:42.228",
      "dateStarted": "2021-02-26 12:06:51.250",
      "dateFinished": "2021-02-26 12:06:51.301",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\nDROP TABLE IF EXISTS doctor_sightings;\n\nCREATE TABLE doctor_sightings (\n  doctor        STRING,\n  sighting_time TIMESTAMP(3),\n  WATERMARK FOR sighting_time AS sighting_time - INTERVAL \u002715\u0027 SECONDS\n)\nWITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027, \n  \u0027fields.doctor.expression\u0027 \u003d \u0027#{dr_who.the_doctors}\u0027,\n  \u0027fields.sighting_time.expression\u0027 \u003d \u0027#{date.past \u0027\u002715\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027\n);\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 14:31:20.266",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268686829_1056396133",
      "id": "paragraph_1614268686829_1056396133",
      "dateCreated": "2021-02-25 23:58:06.829",
      "dateStarted": "2021-03-06 14:31:20.315",
      "dateFinished": "2021-03-06 14:31:50.430",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 10;\n    \n",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 14:32:28.860",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "doctor": "string",
                      "sighting_time": "string",
                      "sightings": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "doctor\tsighting_time\tsightings\nEighth Doctor\t2021-03-06 14:32:59.999\t27617\nEleventh Doctor\t2021-03-06 14:32:59.999\t27630\nFifth Doctor\t2021-03-06 14:32:59.999\t27538\nFourth Doctor\t2021-03-06 14:32:59.999\t27637\nNinth Doctor\t2021-03-06 14:32:59.999\t27828\nSecond Doctor\t2021-03-06 14:32:59.999\t27641\nSeventh Doctor\t2021-03-06 14:32:59.999\t27855\nSixth Doctor\t2021-03-06 14:32:59.999\t27270\nTenth Doctor\t2021-03-06 14:32:59.999\t27716\nThird Doctor\t2021-03-06 14:32:59.999\t27903\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT \n    doctor,\n    TUMBLE_ROWTIME(sighting_time, INTERVAL \u00271\u0027 MINUTE) AS sighting_time,\n    COUNT(*) AS sightings\nFROM doctor_sightings\nGROUP BY \n    TUMBLE(sighting_time, INTERVAL \u00271\u0027 MINUTE),\n    doctor\nORDER BY sighting_time DESC\nLIMIT 10\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:172)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:105)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:89)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callSelect(FlinkSqlInterrpeter.java:494)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callCommand(FlinkSqlInterrpeter.java:257)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.runSqlList(FlinkSqlInterrpeter.java:151)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.internalInterpret(FlinkSqlInterrpeter.java:111)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:47)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:852)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:744)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 73988411c1aae8e37f61c8c49f28674c)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:125)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.client.program.rest.RestClusterClient.lambda$pollResourceAsync$22(RestClusterClient.java:665)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$9(FutureUtils.java:394)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:575)\n\tat java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:943)\n\tat java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456)\n\t... 3 more\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:146)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$null$6(ClusterClientJobClientAdapter.java:123)\n\t... 19 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "http://localhost:8081#/job/73988411c1aae8e37f61c8c49f28674c"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268697349_106287994",
      "id": "paragraph_1614268697349_106287994",
      "dateCreated": "2021-02-25 23:58:17.349",
      "dateStarted": "2021-03-06 14:32:28.917",
      "dateFinished": "2021-03-06 14:33:39.755",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-25 23:58:38.971",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268718968_1902190862",
      "id": "paragraph_1614268718968_1902190862",
      "dateCreated": "2021-02-25 23:58:38.971",
      "status": "READY"
    }
  ],
  "name": "02 Watermarks",
  "id": "2FXSSGYS2",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}