{
  "paragraphs": [
    {
      "text": "%md\n\n\u003cbr/\u003e\n\n\u003e :bulb: This example will show how to calculate an aggregate or cumulative value based on a group of rows using an `OVER` window. A typical use case are rolling aggregations.\n\nThe source table (`temperature_measurements`) is backed by the [`faker` connector](https://flink-packages.org/packages/flink-faker), which continuously generates rows in memory based on Java Faker expressions.\n\nOVER window aggregates compute an aggregated value for every input row over a range of ordered rows. \nIn contrast to GROUP BY aggregates, OVER aggregates do not reduce the number of result rows to a single row for every group. \nInstead, OVER aggregates produce an aggregated value for every input row.\n\nThe order needs to be defined by a [time attribute](https://docs.ververica.com/user_guide/sql_development/table_view.html#time-attributes). \nThe range of rows can be defined by a number of rows or a time interval. \n\nIn this example, we are trying to identify outliers in the `temperature_measurements` table. \nFor this, we use an `OVER` window to calculate, for each measurement, the maximum (`MAX`), minimum (`MIN`) and average (`AVG`) temperature across all measurements, as well as the standard deviation (`STDDEV`), for the same city over the previous minute. \n\u003e As an exercise, you can try to write another query to filter out any temperature measurement that are higher or lower than the average by more than four standard deviations.\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:22:39.515",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cbr/\u003e\n\u003cblockquote\u003e\n\u003cp\u003e💡 This example will show how to calculate an aggregate or cumulative value based on a group of rows using an \u003ccode\u003eOVER\u003c/code\u003e window. A typical use case are rolling aggregations.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe source table (\u003ccode\u003etemperature_measurements\u003c/code\u003e) is backed by the \u003ca href\u003d\"https://flink-packages.org/packages/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e, which continuously generates rows in memory based on Java Faker expressions.\u003c/p\u003e\n\u003cp\u003eOVER window aggregates compute an aggregated value for every input row over a range of ordered rows.\u003cbr /\u003e\nIn contrast to GROUP BY aggregates, OVER aggregates do not reduce the number of result rows to a single row for every group.\u003cbr /\u003e\nInstead, OVER aggregates produce an aggregated value for every input row.\u003c/p\u003e\n\u003cp\u003eThe order needs to be defined by a \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#time-attributes\"\u003etime attribute\u003c/a\u003e.\u003cbr /\u003e\nThe range of rows can be defined by a number of rows or a time interval.\u003c/p\u003e\n\u003cp\u003eIn this example, we are trying to identify outliers in the \u003ccode\u003etemperature_measurements\u003c/code\u003e table.\u003cbr /\u003e\nFor this, we use an \u003ccode\u003eOVER\u003c/code\u003e window to calculate, for each measurement, the maximum (\u003ccode\u003eMAX\u003c/code\u003e), minimum (\u003ccode\u003eMIN\u003c/code\u003e) and average (\u003ccode\u003eAVG\u003c/code\u003e) temperature across all measurements, as well as the standard deviation (\u003ccode\u003eSTDDEV\u003c/code\u003e), for the same city over the previous minute.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAs an exercise, you can try to write another query to filter out any temperature measurement that are higher or lower than the average by more than four standard deviations.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614313116607_1862525193",
      "id": "paragraph_1614313116607_1862525193",
      "dateCreated": "2021-02-26 12:18:36.607",
      "dateStarted": "2021-10-08 16:22:39.515",
      "dateFinished": "2021-10-08 16:22:39.526",
      "status": "FINISHED"
    },
    {
      "text": "%md\n本例将展示如何使用 `OVER` 窗口基于一组数据来计算聚合值或累积值。一个典型的场景是滑动聚合。\n\n例子中使用的 source 表`temperature_measurements` 的数据是利用  [`faker` connector](https://github.com/knaufk/flink-faker) 产生的，它基于 Java Faker 表达式不断的在内存中生成数据。\n\nOVER 窗口聚合对一段有序的数据的每条输入行都计算一个聚合值。与  GROUP BY 聚合不同， OVER 聚合不会将每组的结果记录合并成一条记录。而是为每条输入记录生成一个聚合结果。\n\n顺序需要通过 [time attribute](https://docs.ververica.com/user_guide/sql_development/table_view.html#time-attributes) 定义。记录的范围可以是记录的数量或者是一个时间段。\n\n在本例中，我们试图找出表 `temperature_measurements` 中的异常值。因此，我们使用  `OVER` 窗口对每个城市的每次测量计算前一分钟所有测量的最大 (`MAX`), 最值 (`MIN`) 和 平值 (`AVG`)温度 ，以及他么你的标准差 (`STDDEV`)。\n\n\u003e 作为练习，你可以尝试写一个查询来过滤出所有高于或低于平均值4个标准查的的温度测量。\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:54:32.765",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e本例将展示如何使用 \u003ccode\u003eOVER\u003c/code\u003e 窗口基于一组数据来计算聚合值或累积值。一个典型的场景是滑动聚合。\u003c/p\u003e\n\u003cp\u003e例子中使用的 source 表\u003ccode\u003etemperature_measurements\u003c/code\u003e 的数据是利用  \u003ca href\u003d\"https://github.com/knaufk/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e 产生的，它基于 Java Faker 表达式不断的在内存中生成数据。\u003c/p\u003e\n\u003cp\u003eOVER 窗口聚合对一段有序的数据的每条输入行都计算一个聚合值。与  GROUP BY 聚合不同， OVER 聚合不会将每组的结果记录合并成一条记录。而是为每条输入记录生成一个聚合结果。\u003c/p\u003e\n\u003cp\u003e顺序需要通过 \u003ca href\u003d\"https://docs.ververica.com/user_guide/sql_development/table_view.html#time-attributes\"\u003etime attribute\u003c/a\u003e 定义。记录的范围可以是记录的数量或者是一个时间段。\u003c/p\u003e\n\u003cp\u003e在本例中，我们试图找出表 \u003ccode\u003etemperature_measurements\u003c/code\u003e 中的异常值。因此，我们使用  \u003ccode\u003eOVER\u003c/code\u003e 窗口对每个城市的每次测量计算前一分钟所有测量的最大 (\u003ccode\u003eMAX\u003c/code\u003e), 最值 (\u003ccode\u003eMIN\u003c/code\u003e) 和 平值 (\u003ccode\u003eAVG\u003c/code\u003e)温度 ，以及他么你的标准差 (\u003ccode\u003eSTDDEV\u003c/code\u003e)。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e作为练习，你可以尝试写一个查询来过滤出所有高于或低于平均值4个标准查的的温度测量。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615110707452_60443575",
      "id": "paragraph_1615110707452_60443575",
      "dateCreated": "2021-03-07 09:51:47.452",
      "dateStarted": "2021-03-18 15:54:32.766",
      "dateFinished": "2021-03-18 15:54:32.788",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\nDROP TABLE IF EXISTS temperature_measurements;\n\nCREATE TABLE temperature_measurements (\n  measurement_time TIMESTAMP(3),\n  city STRING,\n  temperature FLOAT, \n  WATERMARK FOR measurement_time AS measurement_time - INTERVAL \u002715\u0027 SECONDS\n)\nCOMMENT \u0027\u0027\nWITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027,\n  \u0027fields.measurement_time.expression\u0027 \u003d \u0027#{date.past \u0027\u002715\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027,\n  \u0027fields.temperature.expression\u0027 \u003d \u0027#{number.numberBetween \u0027\u00270\u0027\u0027,\u0027\u002750\u0027\u0027}\u0027,\n  \u0027fields.city.expression\u0027 \u003d \u0027#{regexify \u0027\u0027(Chicago|Munich|Berlin|Portland|Hangzhou|Seatle|Beijing|New York){1}\u0027\u0027}\u0027\n);\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:23:02.741",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614295390559_156273420",
      "id": "paragraph_1614295390559_156273420",
      "dateCreated": "2021-02-26 07:23:10.559",
      "dateStarted": "2021-10-08 16:23:02.748",
      "dateFinished": "2021-10-08 16:23:34.770",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n  measurement_time,\n  city, \n  temperature,\n  AVG(CAST(temperature AS FLOAT)) OVER last_minute AS avg_temperature_minute,\n  MAX(temperature) OVER last_minute AS min_temperature_minute,\n  MIN(temperature) OVER last_minute AS max_temperature_minute,\n  STDDEV(CAST(temperature AS FLOAT)) OVER last_minute AS stdev_temperature_minute\nFROM temperature_measurements \nWINDOW last_minute AS (\n  PARTITION BY city\n  ORDER BY measurement_time\n  RANGE BETWEEN INTERVAL \u00271\u0027 MINUTE PRECEDING AND CURRENT ROW \n)\nORDER BY measurement_time desc\nLIMIT 100\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:24:10.682",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "measurement_time": "string",
                      "city": "string",
                      "temperature": "string",
                      "avg_temperature_minute": "string",
                      "min_temperature_minute": "string",
                      "max_temperature_minute": "string",
                      "stdev_temperature_minute": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "measurement_time\tcity\ttemperature\tavg_temperature_minute\tmin_temperature_minute\tmax_temperature_minute\tstdev_temperature_minute\n2021-10-08 21:24:28.000\tChicago\t32.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t8.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t40.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t42.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t16.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t23.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t39.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t12.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t6.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t44.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t0.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t43.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t13.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t20.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t22.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t48.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t25.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t31.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t26.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t14.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t25.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t19.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t33.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t19.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t17.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t14.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t13.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t8.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t32.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t19.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t44.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t39.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t46.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t43.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t22.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t36.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t13.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t41.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t17.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t33.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t17.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t17.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t19.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t14.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t1.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t18.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t20.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t14.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t27.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t26.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t41.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t20.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t17.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tChicago\t21.0\t25.19697\t49.0\t0.0\t14.104689\n2021-10-08 21:24:28.000\tMunich\t43.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t48.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t40.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t11.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t22.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t45.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t47.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t14.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t6.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t30.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t26.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t28.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t25.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t7.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t47.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t38.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t24.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t19.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t35.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t11.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t37.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t1.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t10.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t17.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t11.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t41.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t34.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t7.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t34.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t48.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t6.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t36.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t13.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t43.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t0.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t9.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t24.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t19.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t18.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t37.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t3.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t14.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t2.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t3.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t13.0\t24.753527\t49.0\t0.0\t14.280467\n2021-10-08 21:24:28.000\tMunich\t25.0\t24.753527\t49.0\t0.0\t14.280467\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT \n  measurement_time,\n  city, \n  temperature,\n  AVG(CAST(temperature AS FLOAT)) OVER last_minute AS avg_temperature_minute,\n  MAX(temperature) OVER last_minute AS min_temperature_minute,\n  MIN(temperature) OVER last_minute AS max_temperature_minute,\n  STDDEV(CAST(temperature AS FLOAT)) OVER last_minute AS stdev_temperature_minute\nFROM temperature_measurements \nWINDOW last_minute AS (\n  PARTITION BY city\n  ORDER BY measurement_time\n  RANGE BETWEEN INTERVAL \u00271\u0027 MINUTE PRECEDING AND CURRENT ROW \n)\nORDER BY measurement_time desc\nLIMIT 100\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:177)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:109)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:86)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callSelect(FlinkSqlInterpreter.java:494)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callCommand(FlinkSqlInterpreter.java:257)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.runSqlList(FlinkSqlInterpreter.java:151)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.internalInterpret(FlinkSqlInterpreter.java:109)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:55)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:849)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:741)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.flink.client.deployment.application.UnsuccessfulExecutionException: Application Status: CANCELED\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:71)\n\tat org.apache.flink.client.deployment.application.EmbeddedJobClient.lambda$getJobExecutionResult$2(EmbeddedJobClient.java:136)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.client.deployment.application.JobStatusPollingUtils.lambda$null$2(JobStatusPollingUtils.java:101)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:250)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:146)\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:60)\n\t... 52 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "https://knox.c-fa375384f1f481e0.cn-hongkong.emr.aliyuncs.com:8443/gateway/cluster-topo/yarn/proxy/application_1628498781174_4097/#/job/5e551ee29826b5c1da33e4fcaf44f82a"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614295417642_50466260",
      "id": "paragraph_1614295417642_50466260",
      "dateCreated": "2021-02-26 07:23:37.642",
      "dateStarted": "2021-10-08 16:24:10.685",
      "dateFinished": "2021-10-08 16:24:47.609",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-07 11:02:13.353",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615114933343_2063551719",
      "id": "paragraph_1615114933343_2063551719",
      "dateCreated": "2021-03-07 11:02:13.353",
      "status": "READY"
    }
  ],
  "name": "04 Rolling Aggregations on Time Series Data",
  "id": "2G1KSXF73",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}