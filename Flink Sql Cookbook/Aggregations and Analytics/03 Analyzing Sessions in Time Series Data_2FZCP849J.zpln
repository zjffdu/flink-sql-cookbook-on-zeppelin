{
  "paragraphs": [
    {
      "text": "%md\n\n\u003e :bulb: This example will show how to aggregate time-series data in real-time using a `SESSION` window.\n\nThe source table (`server_logs`) is backed by the [`faker` connector](https://flink-packages.org/packages/flink-faker), which continuously generates rows in memory based on Java Faker expressions.\n\n#### What are Session Windows?\n\nIn a [previous recipe](../01_group_by_window/01_group_by_window.md), you learned about _tumbling windows_. Another way to group time-series data is using [_session windows_](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#group-windows), which aggregate records into _sessions_ that represent periods of activity followed by gaps of idleness. Think, for example, of user sessions on a website: a user will be active for a given period of time, then leave the website; and each user will be active at different times. To analyze user behaviour, it\u0027s useful to aggregate their actions on the website for each period of activity (i.e. _session_).\n\nUnlike tumbling windows, session windows don\u0027t have a fixed duration and are tracked independenlty across keys (i.e. windows of different keys will have different durations).\n\n#### Using Session Windows\n\nTo count the number of \"Forbidden\" (403) requests per user over the duration of a session, you can use the `SESSION` built-in group window function. In this example, a session is bounded by a gap of idleness of 10 seconds (`INTERVAL \u002710\u0027 SECOND`). This means that requests that occur within 10 seconds of the last seen request for each user will be merged into the same session window; and any request that occurs outside of this gap will trigger the creation of a new session window.\n\n\u003e Tip: You can use the `SESSION_START` and `SESSION_ROWTIME` [auxiliary functions](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#selecting-group-window-start-and-end-timestamps) to check the lower and upper bounds of session windows.\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:20:12.865",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 563.0,
              "optionOpen": false
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cblockquote\u003e\n\u003cp\u003e💡 This example will show how to aggregate time-series data in real-time using a \u003ccode\u003eSESSION\u003c/code\u003e window.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eThe source table (\u003ccode\u003eserver_logs\u003c/code\u003e) is backed by the \u003ca href\u003d\"https://flink-packages.org/packages/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e, which continuously generates rows in memory based on Java Faker expressions.\u003c/p\u003e\n\u003ch4\u003eWhat are Session Windows?\u003c/h4\u003e\n\u003cp\u003eIn a \u003ca href\u003d\"../01_group_by_window/01_group_by_window.md\"\u003eprevious recipe\u003c/a\u003e, you learned about \u003cem\u003etumbling windows\u003c/em\u003e. Another way to group time-series data is using \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#group-windows\"\u003e\u003cem\u003esession windows\u003c/em\u003e\u003c/a\u003e, which aggregate records into \u003cem\u003esessions\u003c/em\u003e that represent periods of activity followed by gaps of idleness. Think, for example, of user sessions on a website: a user will be active for a given period of time, then leave the website; and each user will be active at different times. To analyze user behaviour, it\u0026rsquo;s useful to aggregate their actions on the website for each period of activity (i.e. \u003cem\u003esession\u003c/em\u003e).\u003c/p\u003e\n\u003cp\u003eUnlike tumbling windows, session windows don\u0026rsquo;t have a fixed duration and are tracked independenlty across keys (i.e. windows of different keys will have different durations).\u003c/p\u003e\n\u003ch4\u003eUsing Session Windows\u003c/h4\u003e\n\u003cp\u003eTo count the number of \u0026ldquo;Forbidden\u0026rdquo; (403) requests per user over the duration of a session, you can use the \u003ccode\u003eSESSION\u003c/code\u003e built-in group window function. In this example, a session is bounded by a gap of idleness of 10 seconds (\u003ccode\u003eINTERVAL \u002710\u0027 SECOND\u003c/code\u003e). This means that requests that occur within 10 seconds of the last seen request for each user will be merged into the same session window; and any request that occurs outside of this gap will trigger the creation of a new session window.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTip: You can use the \u003ccode\u003eSESSION_START\u003c/code\u003e and \u003ccode\u003eSESSION_ROWTIME\u003c/code\u003e \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#selecting-group-window-start-and-end-timestamps\"\u003eauxiliary functions\u003c/a\u003e to check the lower and upper bounds of session windows.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614312835566_170616842",
      "id": "paragraph_1614312835566_170616842",
      "dateCreated": "2021-02-26 12:13:55.566",
      "dateStarted": "2021-10-08 16:20:12.865",
      "dateFinished": "2021-10-08 16:20:12.877",
      "status": "FINISHED"
    },
    {
      "text": "%md\n这个例子将展示如何使用 `SESSION` 窗口来实时聚合时间序列数据。\n\n例子中使用的 source 表`server_logs` 的数据是利用  [`faker` connector](https://github.com/knaufk/flink-faker) 产生的，它基于 Java Faker 表达式不断的在内存中生成数据\n\n#### 什么是 Session 窗口?\n在一个[之前的例子](../01/01_group_by_window.md)中，我们学习了 tumbling 窗口的知识，另一个聚合时间序列数据的方式是使用 [_session windows_](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#group-windows),它将记录聚合到表示活跃时间段的会话中，会话以一段非活跃时间段分割，例如，想想网站上的用户会话：用户将在某个特定的时间段内处于活动状态，然后离开网站；每个用户在不同的时间段处于活动状态。为了分析用户行为，在网站上为每个活动周期（即会话）聚合用户的行为是很有用的。\n\n不像滚动窗口，会话窗口没有固定的持续时间，他对每个 key 独立跟踪(即 不同的 key 有不同的持续时间)\n\n#### 使用 Session 窗口\n为了计算每个用户在一段会话内 \"Forbidden\" (403) 的请求数量，你可以使用内置的 `SESSION` 分组窗口函数。在这个例子中，一个会话被 10 秒(`INTERVAL \u002710\u0027 SECOND`)的非活跃持续时间所分隔，这意味着对于每个用户如果请求与他发送的最后一个请求在 10 秒内，那它们将合并到同一个会话窗口内；并且任何出现在时间间隔外的请求都会触发创建一个新的会话窗口。\n\n\u003e Tip: 你可以使用  `SESSION_START` and `SESSION_ROWTIME` 辅助函数来查看会话窗口的上界和下界。\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:54:19.990",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e这个例子将展示如何使用 \u003ccode\u003eSESSION\u003c/code\u003e 窗口来实时聚合时间序列数据。\u003c/p\u003e\n\u003cp\u003e例子中使用的 source 表\u003ccode\u003eserver_logs\u003c/code\u003e 的数据是利用  \u003ca href\u003d\"https://github.com/knaufk/flink-faker\"\u003e\u003ccode\u003efaker\u003c/code\u003e connector\u003c/a\u003e 产生的，它基于 Java Faker 表达式不断的在内存中生成数据\u003c/p\u003e\n\u003ch4\u003e什么是 Session 窗口?\u003c/h4\u003e\n\u003cp\u003e在一个\u003ca href\u003d\"../01/01_group_by_window.md\"\u003e之前的例子\u003c/a\u003e中，我们学习了 tumbling 窗口的知识，另一个聚合时间序列数据的方式是使用 \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/sql/queries.html#group-windows\"\u003e\u003cem\u003esession windows\u003c/em\u003e\u003c/a\u003e,它将记录聚合到表示活跃时间段的会话中，会话以一段非活跃时间段分割，例如，想想网站上的用户会话：用户将在某个特定的时间段内处于活动状态，然后离开网站；每个用户在不同的时间段处于活动状态。为了分析用户行为，在网站上为每个活动周期（即会话）聚合用户的行为是很有用的。\u003c/p\u003e\n\u003cp\u003e不像滚动窗口，会话窗口没有固定的持续时间，他对每个 key 独立跟踪(即 不同的 key 有不同的持续时间)\u003c/p\u003e\n\u003ch4\u003e使用 Session 窗口\u003c/h4\u003e\n\u003cp\u003e为了计算每个用户在一段会话内 \u0026ldquo;Forbidden\u0026rdquo; (403) 的请求数量，你可以使用内置的 \u003ccode\u003eSESSION\u003c/code\u003e 分组窗口函数。在这个例子中，一个会话被 10 秒(\u003ccode\u003eINTERVAL \u002710\u0027 SECOND\u003c/code\u003e)的非活跃持续时间所分隔，这意味着对于每个用户如果请求与他发送的最后一个请求在 10 秒内，那它们将合并到同一个会话窗口内；并且任何出现在时间间隔外的请求都会触发创建一个新的会话窗口。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTip: 你可以使用  \u003ccode\u003eSESSION_START\u003c/code\u003e and \u003ccode\u003eSESSION_ROWTIME\u003c/code\u003e 辅助函数来查看会话窗口的上界和下界。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615107367214_1369984262",
      "id": "paragraph_1615107367214_1369984262",
      "dateCreated": "2021-03-07 08:56:07.215",
      "dateStarted": "2021-03-18 15:54:19.993",
      "dateFinished": "2021-03-18 15:54:20.011",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n\nDROP TABLE IF EXISTS server_logs;\n\nCREATE TABLE server_logs ( \n    client_ip STRING,\n    client_identity STRING, \n    userid STRING, \n    log_time TIMESTAMP(3),\n    request_line STRING, \n    status_code STRING, \n    WATERMARK FOR log_time AS log_time - INTERVAL \u00275\u0027 SECONDS\n) WITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027, \n  \u0027rows-per-second\u0027 \u003d \u00275\u0027,\n  \u0027fields.client_ip.expression\u0027 \u003d \u0027#{Internet.publicIpV4Address}\u0027,\n  \u0027fields.client_identity.expression\u0027 \u003d  \u0027-\u0027,\n  \u0027fields.userid.expression\u0027 \u003d  \u0027#{regexify \u0027\u0027(morsapaes|knauf|sjwiesman){1}\u0027\u0027}\u0027,\n  \u0027fields.log_time.expression\u0027 \u003d  \u0027#{date.past \u0027\u00275\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027,\n  \u0027fields.request_line.expression\u0027 \u003d \u0027#{regexify \u0027\u0027(GET|POST|PUT|PATCH){1}\u0027\u0027} #{regexify \u0027\u0027(/search\\.html|/login\\.html|/prod\\.html|cart\\.html|/order\\.html){1}\u0027\u0027} #{regexify \u0027\u0027(HTTP/1\\.1|HTTP/2|/HTTP/1\\.0){1}\u0027\u0027}\u0027,\n  \u0027fields.status_code.expression\u0027 \u003d \u0027#{regexify \u0027\u0027(200|201|204|400|401|403|301){1}\u0027\u0027}\u0027\n);\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:20:18.442",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614295272936_2120091148",
      "id": "paragraph_1614295272936_2120091148",
      "dateCreated": "2021-02-26 07:21:12.937",
      "dateStarted": "2021-10-08 16:20:18.443",
      "dateFinished": "2021-10-08 16:20:49.500",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT  \n  userid,\n  SESSION_START(log_time, INTERVAL \u002710\u0027 SECOND) AS session_beg,\n  SESSION_ROWTIME(log_time, INTERVAL \u002710\u0027 SECOND) AS session_end,\n  COUNT(request_line) AS request_cnt\nFROM server_logs\nWHERE status_code \u003d \u0027403\u0027\nGROUP BY \n  userid, \n  SESSION(log_time, INTERVAL \u002710\u0027 SECOND);\n  \n  ",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:20:50.878",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "userid": "string",
                      "session_beg": "string",
                      "session_end": "string",
                      "request_cnt": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "userid\tsession_beg\tsession_end\trequest_cnt\nknauf\t2021-10-08 21:20:48.000\t2021-10-08 21:21:11.999\t5\nsjwiesman\t2021-10-08 21:20:55.000\t2021-10-08 21:21:35.999\t14\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT  \n  userid,\n  SESSION_START(log_time, INTERVAL \u002710\u0027 SECOND) AS session_beg,\n  SESSION_ROWTIME(log_time, INTERVAL \u002710\u0027 SECOND) AS session_end,\n  COUNT(request_line) AS request_cnt\nFROM server_logs\nWHERE status_code \u003d \u0027403\u0027\nGROUP BY \n  userid, \n  SESSION(log_time, INTERVAL \u002710\u0027 SECOND)\njava.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:177)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:109)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:86)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callSelect(FlinkSqlInterpreter.java:494)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.callCommand(FlinkSqlInterpreter.java:257)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.runSqlList(FlinkSqlInterpreter.java:151)\n\tat org.apache.zeppelin.flink.FlinkSqlInterpreter.internalInterpret(FlinkSqlInterpreter.java:109)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:55)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:849)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:741)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.flink.client.deployment.application.UnsuccessfulExecutionException: Application Status: CANCELED\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:71)\n\tat org.apache.flink.client.deployment.application.EmbeddedJobClient.lambda$getJobExecutionResult$2(EmbeddedJobClient.java:136)\n\tat java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)\n\tat java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.client.deployment.application.JobStatusPollingUtils.lambda$null$2(JobStatusPollingUtils.java:101)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$0(AkkaInvocationHandler.java:250)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1389)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:774)\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:750)\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488)\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:1975)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)\n\tat akka.dispatch.OnComplete.internal(Future.scala:300)\n\tat akka.dispatch.OnComplete.internal(Future.scala:297)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)\n\tat akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)\n\tat akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)\n\tat akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)\n\tat akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)\n\tat akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:146)\n\tat org.apache.flink.client.deployment.application.UnsuccessfulExecutionException.fromJobResult(UnsuccessfulExecutionException.java:60)\n\t... 52 more\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "https://knox.c-fa375384f1f481e0.cn-hongkong.emr.aliyuncs.com:8443/gateway/cluster-topo/yarn/proxy/application_1628498781174_4096/#/job/c6ccdfb4df2f9c26a03f0e0e464eda7d"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614295295018_1277184037",
      "id": "paragraph_1614295295018_1277184037",
      "dateCreated": "2021-02-26 07:21:35.018",
      "dateStarted": "2021-10-08 16:20:50.879",
      "dateFinished": "2021-10-08 16:21:45.922",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-26 07:22:12.687",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614295332687_701413513",
      "id": "paragraph_1614295332687_701413513",
      "dateCreated": "2021-02-26 07:22:12.687",
      "status": "READY"
    }
  ],
  "name": "03 Analyzing Sessions in Time Series Data",
  "id": "2FZCP849J",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}