{
  "paragraphs": [
    {
      "text": "%md\n\n\u003e :bulb: In this recipe, we will de-normalize a simple star schema with an n-way temporal table join. \t \n\n[Star schemas](https://en.wikipedia.org/wiki/Star_schema) are a popular way of normalizing data within a data warehouse. At the center of a star schema is a **fact table** whose rows contain metrics, measurements, and other facts about the world. Surrounding fact tables are one or more **dimension tables** which have metadata useful for enriching facts when computing queries.  \nYou are running a small data warehouse for a railroad company which consists of a fact table (`train_activity`) and three dimension tables (`stations`, `booking_channels`, and `passengers`). All inserts to the fact table, and all updates to the dimension tables, are mirrored to Apache Kafka. Records in the fact table are interpreted as inserts only, and so the table is backed by the [standard Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/kafka.html) (`connector` \u003d `kafka`);. In contrast, the records in the dimensional tables are upserts based on a primary key, which requires the [Upsert Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/upsert-kafka.html) (`connector` \u003d `upsert-kafka`).\t \n\nWith Flink SQL you can now easily join all dimensions to our fact table using a 5-way temporal table join. Temporal table joins take an arbitrary table (left input/probe site) and correlate each row to the corresponding rowâ€™s relevant version in a versioned table (right input/build side). Flink uses the SQL syntax of ``FOR SYSTEM_TIME AS OF`` to perform this operation. Using a temporal table join leads to consistent, reproducible results when joining a fact table with more (slowly) changing dimensional tables. Every event (row in the fact table) is joined to its corresponding value of each dimension based on when the event occurred in the real world. \n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 22:59:14.588",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cblockquote\u003e\n\u003cp\u003eğŸ’¡ In this recipe, we will de-normalize a simple star schema with an n-way temporal table join.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Star_schema\"\u003eStar schemas\u003c/a\u003e are a popular way of normalizing data within a data warehouse. At the center of a star schema is a \u003cstrong\u003efact table\u003c/strong\u003e whose rows contain metrics, measurements, and other facts about the world. Surrounding fact tables are one or more \u003cstrong\u003edimension tables\u003c/strong\u003e which have metadata useful for enriching facts when computing queries.\u003cbr /\u003e\nYou are running a small data warehouse for a railroad company which consists of a fact table (\u003ccode\u003etrain_activity\u003c/code\u003e) and three dimension tables (\u003ccode\u003estations\u003c/code\u003e, \u003ccode\u003ebooking_channels\u003c/code\u003e, and \u003ccode\u003epassengers\u003c/code\u003e). All inserts to the fact table, and all updates to the dimension tables, are mirrored to Apache Kafka. Records in the fact table are interpreted as inserts only, and so the table is backed by the \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/kafka.html\"\u003estandard Kafka connector\u003c/a\u003e (\u003ccode\u003econnector\u003c/code\u003e \u003d \u003ccode\u003ekafka\u003c/code\u003e);. In contrast, the records in the dimensional tables are upserts based on a primary key, which requires the \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/upsert-kafka.html\"\u003eUpsert Kafka connector\u003c/a\u003e (\u003ccode\u003econnector\u003c/code\u003e \u003d \u003ccode\u003eupsert-kafka\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eWith Flink SQL you can now easily join all dimensions to our fact table using a 5-way temporal table join. Temporal table joins take an arbitrary table (left input/probe site) and correlate each row to the corresponding rowâ€™s relevant version in a versioned table (right input/build side). Flink uses the SQL syntax of \u003ccode\u003eFOR SYSTEM_TIME AS OF\u003c/code\u003e to perform this operation. Using a temporal table join leads to consistent, reproducible results when joining a fact table with more (slowly) changing dimensional tables. Every event (row in the fact table) is joined to its corresponding value of each dimension based on when the event occurred in the real world.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614305636615_1009654891",
      "id": "paragraph_1614305636615_1009654891",
      "dateCreated": "2021-02-26 10:13:56.615",
      "dateStarted": "2021-10-08 22:59:14.588",
      "dateFinished": "2021-10-08 22:59:14.593",
      "status": "FINISHED"
    },
    {
      "text": "%md\n \nåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ n-way temporal table join æ¥ de-normalize ä¸€ä¸ªç®€å•çš„æ˜Ÿåº§æ¨¡å‹ã€‚\n\n[Star schemas](https://en.wikipedia.org/wiki/Star_schema) æ˜¯ä¸€ä¸ªæµè¡Œçš„åœ¨æ•°æ®ä»“åº“ä¸­ normalizing æ•°æ®çš„æ–¹å¼ã€‚æ˜Ÿåº§æ¨¡å‹çš„ä¸­å¿ƒæ˜¯å«æœ‰æŒ‡æ ‡ã€åº¦é‡å’Œå…¶ä»–å…³äºä¸–ç•Œçš„äº‹å®çš„  **fact table**(äº‹å®è¡¨)ã€‚\n\nå›´ç»•äº‹å®è¡¨çš„æ˜¯ä¸€å¼ æˆ–è€…å¤šå¼  **dimension tables**(ç»´åº¦è¡¨)ï¼Œç»´åº¦è¡¨çš„å…ƒæ•°æ®åœ¨æŸ¥è¯¢è®¡ç®—æ—¶æ˜¯å¯¹äº‹å®è¡¨çš„æ‰©å±•ã€‚\n\nä½ åœ¨ä¸€ä¸ªå°å‹çš„é“è·¯å…¬å¸è¿è¡Œäº†å°å‹æ•°æ®ä»“åº“ï¼Œå®ƒåŒ…å«ä¸€å¼ äº‹å®è¡¨ (`train_activity`) å’Œ3å¼  ç»´åº¦è¡¨ (`stations`, `booking_channels`, and `passengers`)ã€‚æ‰€æœ‰å¯¹äº‹å®è¡¨çš„æ’å…¥å’Œå¯¹ç»´åº¦è¡¨çš„æ›´æ–°éƒ½é•œåƒåˆ° Apache Kafka ä¸­ã€‚äº‹å®è¡¨ä¸­çš„è®°å½•è¡¨ç¤ºä¸ºåªæ’å…¥ï¼Œæ‰€ä»¥å®ƒä½¿ç”¨ [standard Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/kafka.html) (`connector` \u003d `kafka`) æä¾›æ•°æ®ã€‚ç›¸åï¼Œç»´åº¦è¡¨çš„è®°å½•åŸºäºä¸»é”®æ›´æ–°æˆ–è€…æ’å…¥ï¼Œå®ƒéœ€è¦ [Upsert Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/upsert-kafka.html) (`connector` \u003d `upsert-kafka`)ã€‚\n\né€šè¿‡ Flink SQL ä½¿ç”¨ 5-way temporal è¡¨è¿æ¥ï¼Œ ä½ å¯ä»¥è½»æ˜“çš„å°†æ‰€æœ‰çš„ç»´åº¦è¡¨è¿æ¥åˆ°äº‹å®è¡¨ä¸Šã€‚Temporal table joins é‡‡ç”¨ä»»æ„ä¸€å¼ è¡¨(å·¦è¾¹ è¾“å…¥/æ¢é’ˆ åœ°å€)ï¼Œå°†æ¯ä¸€è¡Œè®°å½•ä¸ç‰ˆæœ¬è¡¨ï¼ˆå³è¾¹ è¾“å…¥/æ„å»º ä¾§ï¼‰ä¸­å¯¹åº”è¡Œè®°å½•çš„ç›¸å…³ç‰ˆæœ¬å…³è”ã€‚ä½¿ç”¨ `FOR SYSTEM_TIME AS OF` SQL è¯­æ³•æ¥æ‰§è¡Œè¿™ä¸ªæ“ä½œã€‚å½“å°†äº‹å®è¡¨ä¸å¤šä¸ªç¼“æ…¢å˜åŒ–çš„ç»´åº¦è¡¨è¿æ¥æ˜¯ä½¿ç”¨ä¸€ä¸ª temporal table join å°†äº§å‡ºä¸€è‡´çš„ã€å¯å¤ç°çš„ç»“æœã€‚ æ¯ä¸ªäº‹ä»¶(äº‹å®è¡¨ä¸­çš„ä¸€è¡Œ)ä¸æ¯ä¸ªç»´åº¦è¡¨åŸºäºäº‹ä»¶åœ¨çœŸå®ä¸–ç•Œå‘é€çš„äº‹ä»¶æ¥è¿æ¥å¯¹åº”çš„å€¼ã€‚\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:57:11.460",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ n-way temporal table join æ¥ de-normalize ä¸€ä¸ªç®€å•çš„æ˜Ÿåº§æ¨¡å‹ã€‚\u003c/p\u003e\n\u003cp\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Star_schema\"\u003eStar schemas\u003c/a\u003e æ˜¯ä¸€ä¸ªæµè¡Œçš„åœ¨æ•°æ®ä»“åº“ä¸­ normalizing æ•°æ®çš„æ–¹å¼ã€‚æ˜Ÿåº§æ¨¡å‹çš„ä¸­å¿ƒæ˜¯å«æœ‰æŒ‡æ ‡ã€åº¦é‡å’Œå…¶ä»–å…³äºä¸–ç•Œçš„äº‹å®çš„  \u003cstrong\u003efact table\u003c/strong\u003e(äº‹å®è¡¨)ã€‚\u003c/p\u003e\n\u003cp\u003eå›´ç»•äº‹å®è¡¨çš„æ˜¯ä¸€å¼ æˆ–è€…å¤šå¼  \u003cstrong\u003edimension tables\u003c/strong\u003e(ç»´åº¦è¡¨)ï¼Œç»´åº¦è¡¨çš„å…ƒæ•°æ®åœ¨æŸ¥è¯¢è®¡ç®—æ—¶æ˜¯å¯¹äº‹å®è¡¨çš„æ‰©å±•ã€‚\u003c/p\u003e\n\u003cp\u003eä½ åœ¨ä¸€ä¸ªå°å‹çš„é“è·¯å…¬å¸è¿è¡Œäº†å°å‹æ•°æ®ä»“åº“ï¼Œå®ƒåŒ…å«ä¸€å¼ äº‹å®è¡¨ (\u003ccode\u003etrain_activity\u003c/code\u003e) å’Œ3å¼  ç»´åº¦è¡¨ (\u003ccode\u003estations\u003c/code\u003e, \u003ccode\u003ebooking_channels\u003c/code\u003e, and \u003ccode\u003epassengers\u003c/code\u003e)ã€‚æ‰€æœ‰å¯¹äº‹å®è¡¨çš„æ’å…¥å’Œå¯¹ç»´åº¦è¡¨çš„æ›´æ–°éƒ½é•œåƒåˆ° Apache Kafka ä¸­ã€‚äº‹å®è¡¨ä¸­çš„è®°å½•è¡¨ç¤ºä¸ºåªæ’å…¥ï¼Œæ‰€ä»¥å®ƒä½¿ç”¨ \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/kafka.html\"\u003estandard Kafka connector\u003c/a\u003e (\u003ccode\u003econnector\u003c/code\u003e \u003d \u003ccode\u003ekafka\u003c/code\u003e) æä¾›æ•°æ®ã€‚ç›¸åï¼Œç»´åº¦è¡¨çš„è®°å½•åŸºäºä¸»é”®æ›´æ–°æˆ–è€…æ’å…¥ï¼Œå®ƒéœ€è¦ \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/upsert-kafka.html\"\u003eUpsert Kafka connector\u003c/a\u003e (\u003ccode\u003econnector\u003c/code\u003e \u003d \u003ccode\u003eupsert-kafka\u003c/code\u003e)ã€‚\u003c/p\u003e\n\u003cp\u003eé€šè¿‡ Flink SQL ä½¿ç”¨ 5-way temporal è¡¨è¿æ¥ï¼Œ ä½ å¯ä»¥è½»æ˜“çš„å°†æ‰€æœ‰çš„ç»´åº¦è¡¨è¿æ¥åˆ°äº‹å®è¡¨ä¸Šã€‚Temporal table joins é‡‡ç”¨ä»»æ„ä¸€å¼ è¡¨(å·¦è¾¹ è¾“å…¥/æ¢é’ˆ åœ°å€)ï¼Œå°†æ¯ä¸€è¡Œè®°å½•ä¸ç‰ˆæœ¬è¡¨ï¼ˆå³è¾¹ è¾“å…¥/æ„å»º ä¾§ï¼‰ä¸­å¯¹åº”è¡Œè®°å½•çš„ç›¸å…³ç‰ˆæœ¬å…³è”ã€‚ä½¿ç”¨ \u003ccode\u003eFOR SYSTEM_TIME AS OF\u003c/code\u003e SQL è¯­æ³•æ¥æ‰§è¡Œè¿™ä¸ªæ“ä½œã€‚å½“å°†äº‹å®è¡¨ä¸å¤šä¸ªç¼“æ…¢å˜åŒ–çš„ç»´åº¦è¡¨è¿æ¥æ˜¯ä½¿ç”¨ä¸€ä¸ª temporal table join å°†äº§å‡ºä¸€è‡´çš„ã€å¯å¤ç°çš„ç»“æœã€‚ æ¯ä¸ªäº‹ä»¶(äº‹å®è¡¨ä¸­çš„ä¸€è¡Œ)ä¸æ¯ä¸ªç»´åº¦è¡¨åŸºäºäº‹ä»¶åœ¨çœŸå®ä¸–ç•Œå‘é€çš„äº‹ä»¶æ¥è¿æ¥å¯¹åº”çš„å€¼ã€‚\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615523318129_1784896943",
      "id": "paragraph_1615523318129_1784896943",
      "dateCreated": "2021-03-12 04:28:38.129",
      "dateStarted": "2021-03-18 15:57:11.460",
      "dateFinished": "2021-03-18 15:57:11.471",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n\nDROP TABLE IF EXISTS passengers;\n\nCREATE TABLE passengers (\n  passenger_key STRING, \n  first_name STRING, \n  last_name STRING,\n  update_time TIMESTAMP(3),\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (passenger_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027passengers\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS stations;\n\nCREATE TABLE stations (\n  station_key STRING, \n  update_time TIMESTAMP(3),\n  city STRING,\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (station_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027stations\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS booking_channels;\n\nCREATE TABLE booking_channels (\n  booking_channel_key STRING, \n  update_time TIMESTAMP(3),\n  channel STRING,\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (booking_channel_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027booking_channels\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS train_activities;\n\nCREATE TABLE train_activities (\n  scheduled_departure_time TIMESTAMP(3),\n  actual_departure_date TIMESTAMP(3),\n  passenger_key STRING, \n  origin_station_key STRING, \n  destination_station_key STRING,\n  booking_channel_key STRING,\n  WATERMARK FOR actual_departure_date AS actual_departure_date - INTERVAL \u002710\u0027 SECONDS\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027train_activities\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027,\n  \u0027value.fields-include\u0027 \u003d \u0027ALL\u0027\n);\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:20:14.742",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614316870006_1898527227",
      "id": "paragraph_1614316870006_1898527227",
      "dateCreated": "2021-02-26 13:21:10.006",
      "dateStarted": "2021-02-27 15:20:14.746",
      "dateFinished": "2021-02-27 15:20:15.750",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n  t.actual_departure_date, \n  p.first_name,\n  p.last_name,\n  b.channel, \n  os.city AS origin_station,\n  ds.city AS destination_station\nFROM train_activities t\nLEFT JOIN booking_channels FOR SYSTEM_TIME AS OF t.actual_departure_date AS b \nON t.booking_channel_key \u003d b.booking_channel_key;\nLEFT JOIN passengers FOR SYSTEM_TIME AS OF t.actual_departure_date AS p\nON t.passenger_key \u003d p.passenger_key\nLEFT JOIN stations FOR SYSTEM_TIME AS OF t.actual_departure_date AS os\nON t.origin_station_key \u003d os.station_key\nLEFT JOIN stations FOR SYSTEM_TIME AS OF t.actual_departure_date AS ds\nON t.destination_station_key \u003d ds.station_key\nORDER BY t.actual_departure_date DESC\nLIMIT 10;\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:21:03.980",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614410414745_969940744",
      "id": "paragraph_1614410414745_969940744",
      "dateCreated": "2021-02-27 15:20:14.745",
      "dateStarted": "2021-02-27 15:21:03.984",
      "dateFinished": "2021-02-27 15:21:04.881",
      "status": "ERROR"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:20:55.778",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614410455778_1166301104",
      "id": "paragraph_1614410455778_1166301104",
      "dateCreated": "2021-02-27 15:20:55.778",
      "status": "READY"
    }
  ],
  "name": "05 Real Time Star Schema Denormalization (N-Way Join)",
  "id": "2G1ZCV2GP",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}