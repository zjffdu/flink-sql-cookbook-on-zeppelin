{
  "paragraphs": [
    {
      "text": "%md\n\n![Twitter Badge](https://img.shields.io/badge/Flink%20Version-1.13%2B-lightgrey)\n\n\n\u003e :bulb: In this recipe, you will learn how to use `runAsOne` which is only supported by Zeppelin to run multiple `INSERT INTO` statements in a single, optimized Flink Job.\n\nMany product requirements involve outputting the results of a streaming application to two or more sinks, such as Apache Kafka for real-time use cases, or a Filesystem for offline ones. Other times, two queries are not the same but share some extensive intermediate operations.\n\nWhen working with server logs, the support team would like to see the number of status codes per browser every 5 minutes to have real-time insights into a web pages\u0027 status. Additionally, they would like the same information on an hourly basis made available as partitioned Apache Parquet files so they can perform historical analysis.\n\nWe could quickly write two Flink SQL queries to solve both these requirements, but that would not be efficient. These queries have a lot of duplicated work, like reading the source logs Kafka topic and cleansing the data.\n\nZeppelin includes a feature called `runAsOne`, that allows for multiplexing `INSERT INTO` statements into a single query holistically optimized by Apache Flink and deployed as a single application.\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-08 16:37:50.240",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://img.shields.io/badge/Flink%20Version-1.13%2B-lightgrey\" alt\u003d\"Twitter Badge\" /\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eğŸ’¡ In this recipe, you will learn how to use \u003ccode\u003erunAsOne\u003c/code\u003e which is only supported by Zeppelin to run multiple \u003ccode\u003eINSERT INTO\u003c/code\u003e statements in a single, optimized Flink Job.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eMany product requirements involve outputting the results of a streaming application to two or more sinks, such as Apache Kafka for real-time use cases, or a Filesystem for offline ones. Other times, two queries are not the same but share some extensive intermediate operations.\u003c/p\u003e\n\u003cp\u003eWhen working with server logs, the support team would like to see the number of status codes per browser every 5 minutes to have real-time insights into a web pages\u0026rsquo; status. Additionally, they would like the same information on an hourly basis made available as partitioned Apache Parquet files so they can perform historical analysis.\u003c/p\u003e\n\u003cp\u003eWe could quickly write two Flink SQL queries to solve both these requirements, but that would not be efficient. These queries have a lot of duplicated work, like reading the source logs Kafka topic and cleansing the data.\u003c/p\u003e\n\u003cp\u003eZeppelin includes a feature called \u003ccode\u003erunAsOne\u003c/code\u003e, that allows for multiplexing \u003ccode\u003eINSERT INTO\u003c/code\u003e statements into a single query holistically optimized by Apache Flink and deployed as a single application.\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614268141191_633824219",
      "id": "paragraph_1614268141191_633824219",
      "dateCreated": "2021-02-25 23:49:01.191",
      "dateStarted": "2021-10-08 16:37:50.240",
      "dateFinished": "2021-10-08 16:37:50.246",
      "status": "FINISHED"
    },
    {
      "text": "%md\nåœ¨æœ¬ä¾‹ä¸­ï¼Œä½ å°†å­¦ä¼šæ€ä¹ˆä½¿ç”¨ `runAsOne` æ¥åœ¨å•ä¸ªä¼˜åŒ–çš„Flinkä»»åŠ¡ä¸­è¿è¡Œå¤šä¸ª INSERT INTO è¯­å¥ã€‚\n\nå¾ˆå¤šäº§å“çš„éœ€æ±‚åŒ…å«å°†æµç¨‹åºçš„ç»“æœè¾“å‡ºåˆ°å¤šä¸ªæ¥æ”¶å™¨ï¼Œä¾‹å¦‚å®æ—¶åœºæ™¯çš„ Apache Kafka æˆ–è€… ç¦»çº¿åœºæ™¯çš„æ–‡ä»¶ç³»ç»Ÿã€‚æœ‰æ—¶ï¼Œ2ä¸ªæŸ¥è¯¢å¹¶ä¸ä¸€æ ·ä½†æ˜¯å…±äº«å¾ˆå¤šä¸­é—´æ“ä½œã€‚\n\nåœ¨ä½¿ç”¨æœåŠ¡å™¨æ—¥å¿—æ—¶ï¼Œæ”¯æŒå›¢é˜Ÿå¸Œæœ›æ¯5åˆ†é’ŸæŸ¥çœ‹æ¯ç§æµè§ˆå™¨çš„æ¯ç§çŠ¶æ€ä»£ç æ•°é‡ï¼Œä»¥ä¾¿å®æ—¶äº†è§£webé¡µé¢çš„çŠ¶æ€ã€‚æ­¤å¤–ï¼Œä»–ä»¬è¿˜å¸Œæœ›æ¯å°æ—¶éƒ½èƒ½ä»¥åˆ†çš„åŒºApache Parquetæ–‡ä»¶çš„å½¢å¼æä¾›ç›¸åŒçš„ä¿¡æ¯ï¼Œä»¥ä¾¿æ‰§è¡Œå†å²åˆ†æã€‚\n\næˆ‘ä»¬å¯ä»¥é©¬ä¸Šå†™ 2 ä¸ª Flink SQL æŸ¥è¯¢æ¥è§£å†³è¿™ä¸¤ä¸ªéœ€æ±‚ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼æ•ˆç‡ä¸é«˜ã€‚å› ä¸ºè¿™äº›æŸ¥è¯¢æœ‰å¾ˆå¤šé‡å¤çš„å·¥ä½œï¼Œåƒä¾‹å¦‚ä»Kafka tipic ç§è¯»å–åŸå§‹æ—¥å¿—å’Œæ¸…ç†æ•°æ®ã€‚\n\nZeppelin åŒ…æ‹¬ä¸€ä¸ªç§°ä¸º  `runAsOne` çš„ç‰¹æ€§ï¼Œå®ƒå…è®¸åœ¨å•ä¸ªæŸ¥è¯¢ç§å¤šè·¯å¤ç”¨å¤šä¸ª INSERT INTO è¯­å¥ï¼Œè¿™ä¸ªæŸ¥è¯¢è¢« Apache Flink æ•´ä½“ä¼˜åŒ–ï¼Œå¹¶ä½œä¸ºå•ä¸ªåº”ç”¨ç¨‹åºéƒ¨ç½²ã€‚\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 15:42:36.890",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eåœ¨æœ¬ä¾‹ä¸­ï¼Œä½ å°†å­¦ä¼šæ€ä¹ˆä½¿ç”¨ \u003ccode\u003erunAsOne\u003c/code\u003e æ¥åœ¨å•ä¸ªä¼˜åŒ–çš„Flinkä»»åŠ¡ä¸­è¿è¡Œå¤šä¸ª INSERT INTO è¯­å¥ã€‚\u003c/p\u003e\n\u003cp\u003eå¾ˆå¤šäº§å“çš„éœ€æ±‚åŒ…å«å°†æµç¨‹åºçš„ç»“æœè¾“å‡ºåˆ°å¤šä¸ªæ¥æ”¶å™¨ï¼Œä¾‹å¦‚å®æ—¶åœºæ™¯çš„ Apache Kafka æˆ–è€… ç¦»çº¿åœºæ™¯çš„æ–‡ä»¶ç³»ç»Ÿã€‚æœ‰æ—¶ï¼Œ2ä¸ªæŸ¥è¯¢å¹¶ä¸ä¸€æ ·ä½†æ˜¯å…±äº«å¾ˆå¤šä¸­é—´æ“ä½œã€‚\u003c/p\u003e\n\u003cp\u003eåœ¨ä½¿ç”¨æœåŠ¡å™¨æ—¥å¿—æ—¶ï¼Œæ”¯æŒå›¢é˜Ÿå¸Œæœ›æ¯5åˆ†é’ŸæŸ¥çœ‹æ¯ç§æµè§ˆå™¨çš„æ¯ç§çŠ¶æ€ä»£ç æ•°é‡ï¼Œä»¥ä¾¿å®æ—¶äº†è§£webé¡µé¢çš„çŠ¶æ€ã€‚æ­¤å¤–ï¼Œä»–ä»¬è¿˜å¸Œæœ›æ¯å°æ—¶éƒ½èƒ½ä»¥åˆ†çš„åŒºApache Parquetæ–‡ä»¶çš„å½¢å¼æä¾›ç›¸åŒçš„ä¿¡æ¯ï¼Œä»¥ä¾¿æ‰§è¡Œå†å²åˆ†æã€‚\u003c/p\u003e\n\u003cp\u003eæˆ‘ä»¬å¯ä»¥é©¬ä¸Šå†™ 2 ä¸ª Flink SQL æŸ¥è¯¢æ¥è§£å†³è¿™ä¸¤ä¸ªéœ€æ±‚ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼æ•ˆç‡ä¸é«˜ã€‚å› ä¸ºè¿™äº›æŸ¥è¯¢æœ‰å¾ˆå¤šé‡å¤çš„å·¥ä½œï¼Œåƒä¾‹å¦‚ä»Kafka tipic ç§è¯»å–åŸå§‹æ—¥å¿—å’Œæ¸…ç†æ•°æ®ã€‚\u003c/p\u003e\n\u003cp\u003eZeppelin åŒ…æ‹¬ä¸€ä¸ªç§°ä¸º  \u003ccode\u003erunAsOne\u003c/code\u003e çš„ç‰¹æ€§ï¼Œå®ƒå…è®¸åœ¨å•ä¸ªæŸ¥è¯¢ç§å¤šè·¯å¤ç”¨å¤šä¸ª INSERT INTO è¯­å¥ï¼Œè¿™ä¸ªæŸ¥è¯¢è¢« Apache Flink æ•´ä½“ä¼˜åŒ–ï¼Œå¹¶ä½œä¸ºå•ä¸ªåº”ç”¨ç¨‹åºéƒ¨ç½²ã€‚\u003c/p\u003e\n\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1615107156917_227458529",
      "id": "paragraph_1615107156917_227458529",
      "dateCreated": "2021-03-07 08:52:36.917",
      "dateStarted": "2021-03-18 15:42:36.890",
      "dateFinished": "2021-03-18 15:42:36.904",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\nDROP TEMPORARY TABLE IF EXISTS server_logs_temp;\n\nCREATE TEMPORARY TABLE server_logs_temp ( \n    client_ip       STRING,\n    client_identity STRING, \n    userid          STRING, \n    user_agent      STRING,\n    log_time        TIMESTAMP(3),\n    request_line    STRING, \n    status_code     STRING, \n    size            INT,\n    WATERMARK FOR log_time AS log_time - INTERVAL \u002730\u0027 SECONDS\n) WITH (\n  \u0027connector\u0027 \u003d \u0027faker\u0027, \n  \u0027fields.client_ip.expression\u0027 \u003d \u0027#{Internet.publicIpV4Address}\u0027,\n  \u0027fields.client_identity.expression\u0027 \u003d  \u0027-\u0027,\n  \u0027fields.userid.expression\u0027 \u003d  \u0027-\u0027,\n  \u0027fields.user_agent.expression\u0027 \u003d \u0027#{Internet.userAgentAny}\u0027,\n  \u0027fields.log_time.expression\u0027 \u003d  \u0027#{date.past \u0027\u002715\u0027\u0027,\u0027\u00275\u0027\u0027,\u0027\u0027SECONDS\u0027\u0027}\u0027,\n  \u0027fields.request_line.expression\u0027 \u003d \u0027#{regexify \u0027\u0027(GET|POST|PUT|PATCH){1}\u0027\u0027} #{regexify \u0027\u0027(/search\\.html|/login\\.html|/prod\\.html|cart\\.html|/order\\.html){1}\u0027\u0027} #{regexify \u0027\u0027(HTTP/1\\.1|HTTP/2|/HTTP/1\\.0){1}\u0027\u0027}\u0027,\n  \u0027fields.status_code.expression\u0027 \u003d \u0027#{regexify \u0027\u0027(200|201|204|400|401|403|301){1}\u0027\u0027}\u0027,\n  \u0027fields.size.expression\u0027 \u003d \u0027#{number.numberBetween \u0027\u0027100\u0027\u0027,\u0027\u002710000000\u0027\u0027}\u0027\n);",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 12:37:48.310",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614266965392_2093520683",
      "id": "paragraph_1614266965392_2093520683",
      "dateCreated": "2021-02-25 23:29:25.392",
      "dateStarted": "2021-03-06 12:37:48.455",
      "dateFinished": "2021-03-06 12:37:50.413",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n\nDROP TEMPORARY TABLE IF EXISTS realtime_aggregations_temp;\n\nCREATE TEMPORARY TABLE realtime_aggregations_temp (\n  `browser`     STRING,\n  `status_code` STRING,\n  `end_time`    TIMESTAMP(3),\n  `requests`    BIGINT NOT NULL\n) WITH (\n  \u0027connector\u0027 \u003d \u0027filesystem\u0027,\n  \u0027path\u0027 \u003d \u0027file:///tmp/realtime_aggregations\u0027,\n  \u0027sink.partition-commit.trigger\u0027 \u003d \u0027partition-time\u0027, \n  \u0027format\u0027 \u003d \u0027csv\u0027 \n);\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 12:51:56.712",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614266979082_1973127487",
      "id": "paragraph_1614266979082_1973127487",
      "dateCreated": "2021-02-25 23:29:39.083",
      "dateStarted": "2021-03-06 12:51:56.767",
      "dateFinished": "2021-03-06 12:51:57.217",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n\nDROP TEMPORARY TABLE IF EXISTS offline_datawarehouse_temp;\n\nCREATE TEMPORARY TABLE offline_datawarehouse_temp (\n    `browser`     STRING,\n    `status_code` STRING,\n    `dt`          STRING,\n    `hour`        STRING,\n    `requests`    BIGINT NOT NULL\n) PARTITIONED BY (`dt`, `hour`) WITH (\n  \u0027connector\u0027 \u003d \u0027filesystem\u0027,\n  \u0027path\u0027 \u003d \u0027file:///tmp/offline_datawarehouse\u0027,\n  \u0027sink.partition-commit.trigger\u0027 \u003d \u0027partition-time\u0027, \n  \u0027format\u0027 \u003d \u0027csv\u0027 \n);",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 12:52:00.115",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614267087710_1500021598",
      "id": "paragraph_1614267087710_1500021598",
      "dateCreated": "2021-02-25 23:31:27.710",
      "dateStarted": "2021-03-06 12:52:00.171",
      "dateFinished": "2021-03-06 12:52:00.587",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n-- This is a shared view that will be used by both \n-- insert into statements\nDROP TEMPORARY VIEW IF EXISTS browsers_temp;\n\nCREATE TEMPORARY VIEW browsers_temp AS  \nSELECT \n  REGEXP_EXTRACT(user_agent,\u0027[^\\/]+\u0027) AS browser,\n  status_code,\n  log_time\nFROM server_logs_temp;",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 12:52:05.194",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614267108142_227560020",
      "id": "paragraph_1614267108142_227560020",
      "dateCreated": "2021-02-25 23:31:48.148",
      "dateStarted": "2021-03-06 12:52:05.244",
      "dateFinished": "2021-03-06 12:52:06.166",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(runAsOne\u003dtrue)\n\nINSERT INTO realtime_aggregations_temp\nSELECT\n    browser,\n    status_code,\n    TUMBLE_ROWTIME(log_time, INTERVAL \u00275\u0027 MINUTE) AS end_time,\n    COUNT(*) requests\nFROM browsers_temp\nGROUP BY \n    browser,\n    status_code,\n    TUMBLE(log_time, INTERVAL \u00275\u0027 MINUTE);\n    \nINSERT INTO offline_datawarehouse_temp\nSELECT\n    browser,\n    status_code,\n    DATE_FORMAT(TUMBLE_ROWTIME(log_time, INTERVAL \u00271\u0027 HOUR), \u0027yyyy-MM-dd\u0027) AS `dt`,\n    DATE_FORMAT(TUMBLE_ROWTIME(log_time, INTERVAL \u00271\u0027 HOUR), \u0027HH\u0027) AS `hour`,\n    COUNT(*) requests\nFROM browsers_temp\nGROUP BY \n    browser,\n    status_code,\n    TUMBLE(log_time, INTERVAL \u00271\u0027 HOUR);\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-06 12:53:27.697",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "http://localhost:8081#/job/90ffa75345c515c217dce8ae51859fbd"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614267128467_2138149264",
      "id": "paragraph_1614267128467_2138149264",
      "dateCreated": "2021-02-25 23:32:08.467",
      "dateStarted": "2021-03-06 12:53:27.733",
      "dateFinished": "2021-03-06 12:53:34.465",
      "status": "ABORT"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-25 23:33:34.659",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614267214658_1658872109",
      "id": "paragraph_1614267214658_1658872109",
      "dateCreated": "2021-02-25 23:33:34.658",
      "status": "READY"
    }
  ],
  "name": "08 Writing Results into Multiple Tables",
  "id": "2G1MEGYE2",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}